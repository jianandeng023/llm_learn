{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:love, with score:0.642368495464325\n",
      "label:anger, with score:0.7687773108482361\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 加载下载好的模型方法\n",
    "model_path = 'D:/hug_model/text_cls'\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model_path)\n",
    "\n",
    "classifier(\"I've been waiting for a Hugging Face course my whole life.\")\n",
    "\n",
    "\n",
    "# 列表输出\n",
    "result = classifier([\"I love programming in Python\",\n",
    "                     \"I hate programming in C++\"])\n",
    "for r in result:\n",
    "    print(f\"label:{r['label']}, with score:{r['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: D:\\hug_model\\models\\Qwen\\Qwen3-0.6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 09:20:06,537 - modelscope - INFO - Creating symbolic link [D:\\hug_model\\models\\Qwen\\Qwen3-0.6B].\n",
      "2025-05-05 09:20:06,539 - modelscope - WARNING - Failed to create symbolic link D:\\hug_model\\models\\Qwen\\Qwen3-0.6B for D:\\hug_model\\models\\Qwen\\Qwen3-0___6B.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [40, 2948, 56707, 1054, 0], 'attention_mask': [1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "from modelscope.hub.snapshot_download import snapshot_download\n",
    "from transformers import AutoTokenizer\n",
    "model_dir = snapshot_download(\"Qwen/Qwen3-0.6B\")\n",
    "model_path = \"D:/hug_model/models/Qwen/Qwen3-0___6B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "encoding = tokenizer(\"I love Chengdu!\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 151, 11157, 35469, 11652, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n",
      "{'input_ids': tensor([[  101,   151, 11157, 35469, 11652,   106,   102,     0,     0],\n",
      "        [  101,   151, 39487, 23515, 10104,   145,   116,   116,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# AutoTokenizer的简要使用\n",
    "# 使用AutoTokenizer加载一个分词器\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# model_name = \"nlptown/bert-base-uncased-finetuned-sst-2-english\" # 这种是使用API自动下载预训练模型\n",
    "# 预先下载到本地的模型\n",
    "model_name = \"D:/hug_model/nlptown\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 传入待分词的文本\n",
    "eocoding = tokenizer(\"I love Chengdu!\")\n",
    "print(eocoding)\n",
    "# 分词返回字典包括：input_ids:用数字表示的token, attention_mask：应该关注哪些token的指示。\n",
    "\n",
    "\n",
    "# 也可以接受列表作为输入\n",
    "pt_batch = tokenizer(\n",
    "    [\"I love Chengdu!\", \"I hate programming in C++\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "print(pt_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0048, 0.0044, 0.0194, 0.1275, 0.8439],\n",
      "        [0.6015, 0.2285, 0.0586, 0.0417, 0.0697]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# AutoModel的简要使用\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"D:/hug_model/nlptown\"\n",
    "\n",
    "# 加载模型\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "# 使用模型进行推理\n",
    "outputs = pt_model(**pt_batch)\n",
    "\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# 模型在 logits 属性输出最终的激活结果. \n",
    "# 在 logits 上应用 softmax 函数来查询概率:\n",
    "pt_predictions = F.softmax(outputs.logits, dim=-1)\n",
    "print(pt_predictions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存模型\n",
    "# 当模型微调完成后，可以使用PreTrainedModel.save_pretrained()\n",
    "# 把模型和它的分词器保存下来。\n",
    "\n",
    "pt_save_path = \"../models/pt_save_pretrained\"\n",
    "tokenizer.save_pretrained(pt_save_path)\n",
    "pt_model.save_pretrained(pt_save_path)\n",
    "\n",
    "# 当下次使用这个模型的时候，可以使用PreTrainedModel.from_pretrained()加载\n",
    "# pt_model = AutoModelForSequenceClassification.from_pretrained(\"../models/pt_save_pretrained\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformers可以将保存模型加载成为另一个框架模型\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(pt_save_path)\n",
    "tf_model = TFAutoModelForSequenceClassification.from_pretrained(pt_save_path, from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoConfig\n",
    "from transformers import AutoConfig, AutoModel\n",
    "my_config = AutoConfig.from_pretrained(\"../models/pt_save_pretrained\", n_head=12)\n",
    "\n",
    "my_model = AutoModel.from_config(my_config) # 从自定义的配置文件加载配置文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer-pytorch优化训练循环\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
