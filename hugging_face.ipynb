{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label:love, with score:0.642368495464325\n",
      "label:anger, with score:0.7687773108482361\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 加载下载好的模型方法\n",
    "model_path = 'D:/hug_model/text_cls'\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model_path)\n",
    "\n",
    "classifier(\"I've been waiting for a Hugging Face course my whole life.\")\n",
    "\n",
    "\n",
    "# 列表输出\n",
    "result = classifier([\"I love programming in Python\",\n",
    "                     \"I hate programming in C++\"])\n",
    "for r in result:\n",
    "    print(f\"label:{r['label']}, with score:{r['score']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "\n",
    "dataset = load_dataset(\"PolyAI/minds14\", name=\"en-US\", split=\"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: D:\\hug_model\\models\\Qwen\\Qwen3-0.6B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-05 09:20:06,537 - modelscope - INFO - Creating symbolic link [D:\\hug_model\\models\\Qwen\\Qwen3-0.6B].\n",
      "2025-05-05 09:20:06,539 - modelscope - WARNING - Failed to create symbolic link D:\\hug_model\\models\\Qwen\\Qwen3-0.6B for D:\\hug_model\\models\\Qwen\\Qwen3-0___6B.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [40, 2948, 56707, 1054, 0], 'attention_mask': [1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "from modelscope.hub.snapshot_download import snapshot_download\n",
    "from transformers import AutoTokenizer\n",
    "model_dir = snapshot_download(\"Qwen/Qwen3-0.6B\")\n",
    "model_path = \"D:/hug_model/models/Qwen/Qwen3-0___6B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "encoding = tokenizer(\"I love Chengdu!\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 151, 11157, 35469, 11652, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}\n",
      "{'input_ids': tensor([[  101,   151, 11157, 35469, 11652,   106,   102,     0,     0],\n",
      "        [  101,   151, 39487, 23515, 10104,   145,   116,   116,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# AutoTokenizer的简要使用\n",
    "# 使用AutoTokenizer加载一个分词器\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# model_name = \"nlptown/bert-base-uncased-finetuned-sst-2-english\" # 这种是使用API自动下载预训练模型\n",
    "# 预先下载到本地的模型\n",
    "model_name = \"D:/hug_model/nlptown\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 传入待分词的文本\n",
    "eocoding = tokenizer(\"I love Chengdu!\")\n",
    "print(eocoding)\n",
    "# 分词返回字典包括：input_ids:用数字表示的token, attention_mask：应该关注哪些token的指示。\n",
    "\n",
    "# 也可以接受列表作为输入\n",
    "pt_batch = tokenizer(\n",
    "    [\"I love Chengdu!\", \"I hate programming in C++\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "print(pt_batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoModel的简要使用"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
